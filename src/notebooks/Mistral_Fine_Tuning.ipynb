{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mistral 7B Fine Tuning"
      ],
      "metadata": {
        "id": "YOdsiZJM9WQV"
      },
      "id": "YOdsiZJM9WQV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing and importing necessary packages"
      ],
      "metadata": {
        "id": "oZF1IHSV9a4l"
      },
      "id": "oZF1IHSV9a4l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9134fe2-c867-40dc-af14-bd7f1f7c9cb8",
      "metadata": {
        "id": "d9134fe2-c867-40dc-af14-bd7f1f7c9cb8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "if major_version >= 7:\n",
        "    print(\"new\")\n",
        "\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "else:\n",
        "\n",
        "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b934b61e-4085-4606-8787-dcf4bbdd0a49",
      "metadata": {
        "id": "b934b61e-4085-4606-8787-dcf4bbdd0a49",
        "outputId": "c267f2e9-4cd8-490b-cfc1-885d34cb6eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting weave\n",
            "  Obtaining dependency information for weave from https://files.pythonhosted.org/packages/55/f0/2e7d81f47440e8a839d8c2e737702c5f4c5f8c8050fec40e2ef83c3c83e7/weave-0.50.1-py3-none-any.whl.metadata\n",
            "  Downloading weave-0.50.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in ./gearchain/lib/python3.11/site-packages (from weave) (4.11.0)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in ./gearchain/lib/python3.11/site-packages (from weave) (16.0.0)\n",
            "Collecting openai>=1.0.0 (from weave)\n",
            "  Obtaining dependency information for openai>=1.0.0 from https://files.pythonhosted.org/packages/32/54/e50ba99d35dd951f5ca94c54cb7fe2f492c8a3a87e5979e21194cccd1977/openai-1.25.0-py3-none-any.whl.metadata\n",
            "  Downloading openai-1.25.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tiktoken>=0.4.0 (from weave)\n",
            "  Obtaining dependency information for tiktoken>=0.4.0 from https://files.pythonhosted.org/packages/63/ec/3856d242f580d0d755c3be9024dd11b17b3363dd0c7c3000e3bdecb40d84/tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pydantic>=2.0.0 (from weave)\n",
            "  Obtaining dependency information for pydantic>=2.0.0 from https://files.pythonhosted.org/packages/ed/76/9a17032880ed27f2dbd490c77a3431cbc80f47ba81534131de3c2846e736/pydantic-2.7.1-py3-none-any.whl.metadata\n",
            "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.7.0 in ./gearchain/lib/python3.11/site-packages (from weave) (13.7.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.3 in ./gearchain/lib/python3.11/site-packages (from weave) (3.9.5)\n",
            "Collecting aiofiles>=22.1.0 (from weave)\n",
            "  Obtaining dependency information for aiofiles>=22.1.0 from https://files.pythonhosted.org/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl.metadata\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting aioprocessing>=2.0.1 (from weave)\n",
            "  Obtaining dependency information for aioprocessing>=2.0.1 from https://files.pythonhosted.org/packages/ea/7b/34129c3bb87078f37b1ca64b547e8669fdde00db9fa724f0b3a8ec54bb27/aioprocessing-2.0.1-py3-none-any.whl.metadata\n",
            "  Downloading aioprocessing-2.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting Werkzeug>=2.0.0 (from weave)\n",
            "  Obtaining dependency information for Werkzeug>=2.0.0 from https://files.pythonhosted.org/packages/e3/23/c9843d7550092ae7ad380611c238f44afef66f58f76c1dab7dcf313e4339/werkzeug-3.0.2-py3-none-any.whl.metadata\n",
            "  Using cached werkzeug-3.0.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting janus>=1.0.0 (from weave)\n",
            "  Obtaining dependency information for janus>=1.0.0 from https://files.pythonhosted.org/packages/c1/84/7bfe436fa6a4943eecb17c2cca9c84215299684575376d664ea6bf294439/janus-1.0.0-py3-none-any.whl.metadata\n",
            "  Downloading janus-1.0.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in ./gearchain/lib/python3.11/site-packages (from weave) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.21 in ./gearchain/lib/python3.11/site-packages (from weave) (1.26.4)\n",
            "Requirement already satisfied: wandb>=0.16.4 in ./gearchain/lib/python3.11/site-packages (from weave) (0.16.6)\n",
            "Collecting graphql-core>3 (from weave)\n",
            "  Obtaining dependency information for graphql-core>3 from https://files.pythonhosted.org/packages/f8/39/e5143e7ec70939d2076c1165ae9d4a3815597019c4d797b7f959cf778600/graphql_core-3.2.3-py3-none-any.whl.metadata\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gql[requests]>=3.4.1 (from weave)\n",
            "  Obtaining dependency information for gql[requests]>=3.4.1 from https://files.pythonhosted.org/packages/74/fb/01a200e1c31b79690427c8e983014e4220d2652b4372a46fe4598e1d7a8e/gql-3.5.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading gql-3.5.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting analytics-python>=1.2.9 (from weave)\n",
            "  Obtaining dependency information for analytics-python>=1.2.9 from https://files.pythonhosted.org/packages/67/84/d41972eeddd7299bd2e2246a9be78abba46f2d255c0c435c64748cd99088/analytics_python-1.4.post1-py2.py3-none-any.whl.metadata\n",
            "  Downloading analytics_python-1.4.post1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: packaging>=21.0 in ./gearchain/lib/python3.11/site-packages (from weave) (24.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./gearchain/lib/python3.11/site-packages (from aiohttp>=3.8.3->weave) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./gearchain/lib/python3.11/site-packages (from aiohttp>=3.8.3->weave) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./gearchain/lib/python3.11/site-packages (from aiohttp>=3.8.3->weave) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./gearchain/lib/python3.11/site-packages (from aiohttp>=3.8.3->weave) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./gearchain/lib/python3.11/site-packages (from aiohttp>=3.8.3->weave) (1.9.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in ./gearchain/lib/python3.11/site-packages (from analytics-python>=1.2.9->weave) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in ./gearchain/lib/python3.11/site-packages (from analytics-python>=1.2.9->weave) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from analytics-python>=1.2.9->weave)\n",
            "  Obtaining dependency information for monotonic>=1.5 from https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl.metadata\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff==1.10.0 (from analytics-python>=1.2.9->weave)\n",
            "  Obtaining dependency information for backoff==1.10.0 from https://files.pythonhosted.org/packages/f0/32/c5dd4f4b0746e9ec05ace2a5045c1fc375ae67ee94355344ad6c7005fd87/backoff-1.10.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in ./gearchain/lib/python3.11/site-packages (from analytics-python>=1.2.9->weave) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of gql[requests] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gql[requests]>=3.4.1 (from weave)\n",
            "  Obtaining dependency information for gql[requests]>=3.4.1 from https://files.pythonhosted.org/packages/64/1c/2facac9c192d4470960537cf8cdf92d41af10e300a8095ebc37740b4df38/gql-3.4.1-py2.py3-none-any.whl.metadata\n",
            "  Downloading gql-3.4.1-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting analytics-python>=1.2.9 (from weave)\n",
            "  Obtaining dependency information for analytics-python>=1.2.9 from https://files.pythonhosted.org/packages/ce/d8/f6e254164bdff3431273b8a41fb2e87f9b996e7923bd1e560b40f7c71c6f/analytics_python-1.4.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Obtaining dependency information for analytics-python>=1.2.9 from https://files.pythonhosted.org/packages/30/81/2f447982f8d5dec5b56c10ca9ac53e5de2b2e9e2bdf7e091a05731f21379/analytics_python-1.3.1-py2.py3-none-any.whl.metadata\n",
            "  Downloading analytics_python-1.3.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Obtaining dependency information for analytics-python>=1.2.9 from https://files.pythonhosted.org/packages/d3/37/c49d052f88655cd96445c36979fb63f69ef859e167eaff5706ca7c8a8ee3/analytics_python-1.2.9-py2.py3-none-any.whl.metadata\n",
            "  Downloading analytics_python-1.2.9-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests]>=3.4.1->weave)\n",
            "  Obtaining dependency information for backoff<3.0,>=1.11.1 from https://files.pythonhosted.org/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl.metadata\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.0 in ./gearchain/lib/python3.11/site-packages (from gql[requests]>=3.4.1->weave) (4.3.0)\n",
            "Collecting requests-toolbelt<2,>=1.0.0 (from gql[requests]>=3.4.1->weave)\n",
            "  Obtaining dependency information for requests-toolbelt<2,>=1.0.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.0.0->weave)\n",
            "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./gearchain/lib/python3.11/site-packages (from openai>=1.0.0->weave) (0.27.0)\n",
            "Requirement already satisfied: sniffio in ./gearchain/lib/python3.11/site-packages (from openai>=1.0.0->weave) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./gearchain/lib/python3.11/site-packages (from openai>=1.0.0->weave) (4.66.2)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0.0->weave)\n",
            "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic-core==2.18.2 (from pydantic>=2.0.0->weave)\n",
            "  Obtaining dependency information for pydantic-core==2.18.2 from https://files.pythonhosted.org/packages/80/b8/b93d756b36425f7ad378dcb9fdf5f6a03b88afaae0476f7bdb31dd8964be/pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./gearchain/lib/python3.11/site-packages (from rich>=13.7.0->weave) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./gearchain/lib/python3.11/site-packages (from rich>=13.7.0->weave) (2.17.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./gearchain/lib/python3.11/site-packages (from tiktoken>=0.4.0->weave) (2024.4.16)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (3.1.43)\n",
            "Requirement already satisfied: psutil>=5.0.0 in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (5.9.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (2.0.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (1.3.3)\n",
            "Requirement already satisfied: setuptools in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (65.5.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in ./gearchain/lib/python3.11/site-packages (from wandb>=0.16.4->weave) (3.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./gearchain/lib/python3.11/site-packages (from Werkzeug>=2.0.0->weave) (2.1.5)\n",
            "Requirement already satisfied: idna>=2.8 in ./gearchain/lib/python3.11/site-packages (from anyio<5,>=3.0->gql[requests]>=3.4.1->weave) (3.7)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./gearchain/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave) (4.0.11)\n",
            "Requirement already satisfied: certifi in ./gearchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->weave) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in ./gearchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->weave) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./gearchain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->weave) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./gearchain/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.0->weave) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./gearchain/lib/python3.11/site-packages (from requests<3.0,>=2.7->analytics-python>=1.2.9->weave) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./gearchain/lib/python3.11/site-packages (from requests<3.0,>=2.7->analytics-python>=1.2.9->weave) (2.2.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./gearchain/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave) (5.0.1)\n",
            "Downloading weave-0.50.1-py3-none-any.whl (28.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading aioprocessing-2.0.1-py3-none-any.whl (14 kB)\n",
            "Downloading analytics_python-1.2.9-py2.py3-none-any.whl (13 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading janus-1.0.0-py3-none-any.whl (6.9 kB)\n",
            "Downloading openai-1.25.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached werkzeug-3.0.2-py3-none-any.whl (226 kB)\n",
            "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Werkzeug, pydantic-core, janus, graphql-core, distro, backoff, annotated-types, aioprocessing, aiofiles, tiktoken, requests-toolbelt, pydantic, gql, analytics-python, openai, weave\n",
            "Successfully installed Werkzeug-3.0.2 aiofiles-23.2.1 aioprocessing-2.0.1 analytics-python-1.2.9 annotated-types-0.6.0 backoff-2.2.1 distro-1.9.0 gql-3.5.0 graphql-core-3.2.3 janus-1.0.0 openai-1.25.0 pydantic-2.7.1 pydantic-core-2.18.2 requests-toolbelt-1.0.0 tiktoken-0.6.0 weave-0.50.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: wandb in ./gearchain/lib/python3.11/site-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in ./gearchain/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in ./gearchain/lib/python3.11/site-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in ./gearchain/lib/python3.11/site-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in ./gearchain/lib/python3.11/site-packages (from wandb) (5.9.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in ./gearchain/lib/python3.11/site-packages (from wandb) (2.0.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in ./gearchain/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in ./gearchain/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in ./gearchain/lib/python3.11/site-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in ./gearchain/lib/python3.11/site-packages (from wandb) (65.5.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in ./gearchain/lib/python3.11/site-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in ./gearchain/lib/python3.11/site-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in ./gearchain/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./gearchain/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./gearchain/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./gearchain/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./gearchain/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./gearchain/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./gearchain/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install weave\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "228c845e-2e07-4d48-9031-3703c22b61e3",
      "metadata": {
        "id": "228c845e-2e07-4d48-9031-3703c22b61e3",
        "outputId": "c048f776-d238-4d20-f056-40b83cad4350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup Weights & Biases for experiment tracking.\n",
        "import wandb\n",
        "wandb.login()             # create account on wandb and copy paste the token here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc93e8a-a8c6-453b-b54d-75044d87efaa",
      "metadata": {
        "id": "ddc93e8a-a8c6-453b-b54d-75044d87efaa",
        "outputId": "7463e13e-0399-40c1-fda0-c13d0124008f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/aneeqkarimmalik/notebooks/wandb/run-20240501_071415-4h6wczwz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/med_scribe/soap-comparision/runs/4h6wczwz' target=\"_blank\">mistral-7b</a></strong> to <a href='https://wandb.ai/med_scribe/soap-comparision' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/med_scribe/soap-comparision' target=\"_blank\">https://wandb.ai/med_scribe/soap-comparision</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/med_scribe/soap-comparision/runs/4h6wczwz' target=\"_blank\">https://wandb.ai/med_scribe/soap-comparision/runs/4h6wczwz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/med_scribe/soap-comparision/runs/4h6wczwz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fb20928ff50>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project=\"soap-comparision\", name = \"mistral-7b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Fine Tuning"
      ],
      "metadata": {
        "id": "1abzvrS392jH"
      },
      "id": "1abzvrS392jH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c30ee9b7-11ea-4b3a-9c74-675f4eb1ea9e",
      "metadata": {
        "id": "c30ee9b7-11ea-4b3a-9c74-675f4eb1ea9e",
        "outputId": "39ceab3e-4e80-4cb2-b2d9-751fd755bf3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aneeqkarimmalik/notebooks/gearchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.4\n",
            "   \\\\   /|    GPU: NVIDIA L4. Max memory: 21.964 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.22.post7. FA = True.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        }
      ],
      "source": [
        "# import packages\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# Define the configuration for the model including maximum sequence length and datatype.\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
        "    \"unsloth/llama-2-13b-bnb-4bit\",\n",
        "    \"unsloth/codellama-34b-bnb-4bit\",\n",
        "    \"unsloth/tinyllama-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2b-bnb-4bit\",\n",
        "]\n",
        "\n",
        "# Load a pretrained Large Language Model from the Unsloth library. This step initializes the Mistral 7B model,\n",
        "# specifically configured to work with 4-bit quantized weights for efficient computation.\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9d02e29-4a8e-4a1e-aa41-5e1c8553dbe4",
      "metadata": {
        "id": "b9d02e29-4a8e-4a1e-aa41-5e1c8553dbe4",
        "outputId": "bcf218a7-86f5-4ed1-b4a5-be0ba65847aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "# Enhance the model using Parameter-Efficient Fine-Tuning (PEFT) technique\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 8,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed104fd9-3149-456c-8697-390d89b7f367",
      "metadata": {
        "id": "ed104fd9-3149-456c-8697-390d89b7f367",
        "outputId": "17495f8f-1296-45ef-fd11-1fab89b1b156"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3638.03 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Define a structured prompt template for generating AI responses based on a given task.\n",
        "soap_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "# Tokenizes and formats dataset examples into a structured text format for model training.\n",
        "# This function takes in examples with 'Instruction', 'context', and 'response' fields,\n",
        "# applies the predefined soap_prompt template, and appends an End-Of-Sequence token to signify the end of each input.\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"Instruction\"]\n",
        "    inputs       = examples[\"context\"]\n",
        "    outputs      = examples[\"response\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "\n",
        "        text = soap_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "# imports the dataset from hugging face\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"m-masood/synthetic-soap-dataset\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a3d9b63-7489-4f83-b77f-40a64af4f2fc",
      "metadata": {
        "id": "0a3d9b63-7489-4f83-b77f-40a64af4f2fc",
        "outputId": "fea0a6fc-47fa-406f-d259-eadb6d77ae09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=2): 100%|████████████████████████████████████████████| 1000/1000 [00:03<00:00, 279.45 examples/s]\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Initialize the SFTTrainer for fine-tuning the language model with specific training configurations.\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        report_to = \"wandb\",\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 20,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3f51161-d1ff-496f-977c-59792ed0379e",
      "metadata": {
        "id": "b3f51161-d1ff-496f-977c-59792ed0379e",
        "outputId": "2a84514d-b295-4e2e-b104-c10201986357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = NVIDIA L4. Max memory = 21.964 GB.\n",
            "4.547 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# Monitoring gpu status\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")\n",
        "wandb.log({\"GPU Stats\": gpu_stats.name,\n",
        "           \"Max Memory\":max_memory,\n",
        "           \"Reserved Memory\":start_gpu_memory })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f798fb34-8ff2-4434-b41f-5ed2611df058",
      "metadata": {
        "id": "f798fb34-8ff2-4434-b41f-5ed2611df058",
        "outputId": "befc4c16-75a1-4cb7-b259-a53525fc2935"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 20\n",
            " \"-____-\"     Number of trainable parameters = 20,971,520\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 06:08, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.479500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.536300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.474600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.448600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.363900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.362200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.458200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.386400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.224200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.361400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.303500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.376800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.279400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.372400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.189400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.307100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.282400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.192700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.263800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.252700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Starting model fine tuning\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e05eed8b-4a0e-4b3b-92c8-0fc684398484",
      "metadata": {
        "id": "e05eed8b-4a0e-4b3b-92c8-0fc684398484",
        "outputId": "92a8434a-4e96-4e02-a494-f9e978158893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390.6233 seconds used for training.\n",
            "6.51 minutes used for training.\n",
            "Peak reserved memory = 6.076 GB.\n",
            "Peak reserved memory for training = 1.529 GB.\n",
            "Peak reserved memory % of max memory = 27.663 %.\n",
            "Peak reserved memory for training % of max memory = 6.961 %.\n"
          ]
        }
      ],
      "source": [
        "# Monitoring stats for GPU utilization during training\n",
        "\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n",
        "\n",
        "wandb.log({\"Training Time(Seconds)\": trainer_stats.metrics['train_runtime'],\n",
        "           \"Max Memory\":max_memory,\n",
        "           \"Memory Reserved for Training(GB)\":used_memory_for_lora ,\n",
        "          \"Percentage of Max Memory Reserved for Training(%)\":lora_percentage })"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference"
      ],
      "metadata": {
        "id": "L0t1HU_ECbWg"
      },
      "id": "L0t1HU_ECbWg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f010d81-f34c-4e61-871e-286a500146de",
      "metadata": {
        "id": "4f010d81-f34c-4e61-871e-286a500146de",
        "outputId": "606062ae-a203-47d0-a2f8-242d6bdb21bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nBelow is an dialogue that shows conversation between doctor and patient, convert it into clinical soap format.\\n\\n### Input:\\nD: How may I help you? P: I'm here because um I've been having some pain in my left knee for the past two months and it's not getting better. It feels stiff and um I just haven't been able to uh, you know, use it as well, as well as I was using it before um and it's just limited some of my daily activities. D: OK, um, and where, uh so it's, the pain is in your left knee. Where are you feeling this pain specifically? Is it at the front of the knee, the sides, or or the the back? Could you point to it? P: It feels like it's mostly on the front. D: OK. P: Like deep within that um kneecap. D: OK, and you said the pain started two months ago? P: Yes, well, it's always been a little like tender. Um but now it's more painful. D: OK. And so, so has it been getting worse? P: I would say so, slowly getting worse. D: OK. Uh and when you get uh pain in the left knee, how long does it typically last for? P: It usually hurts while I'm doing, while I'm moving it, or just after, but if I if I rest, the pain eventually goes away. Um but when I first wake up in the morning, that joint feels stiff. And then when I start using it, using it more, it's less stiff, but it becomes painful. D: OK, so you have some stiffness in the morning? P: I do. D: OK, and how long does it last for? Like 30 minutes, 60 minutes or or longer? P: The stiffness or pain? D: Yeah, the the stiffness. P: Uh the stiffness goes away in like yeah 15 to 30 minutes. D: OK, and how would you describe the pain, um in terms of its character? P: It feels, it feels uh, I guess most of the time it's like it's like a dull kind of pain, but it can be sharp. D: OK, and is there anything that makes the pain worse? P: Just with a lot of activity it gets worse. D: And you feel it radiate anywhere else? P: No. D: OK, and how would you describe the severity of your pain on a scale of 10 being the worst pain you've ever felt, and 1 being kind of very minimal pain. P: Uhm, I would give it maybe uh 7. D: OK. And have you had any injuries to your knee before? P: No, not that I can think of. D: No, OK. Um and have you been having any uh any weight loss recently? P: Uh no, weight gain. D: Weight gain, OK. How much weight have you gained over the last uh several months? P: Over the past six months, I'd say I've gained about 20 pounds. D: OK, have you had changes in your diet and or exercise? P: Um I guess I've been eating a little bit more, um but no changes in exercise. D: OK. Um have you been having any fevers or chills? P: No. D: OK, how about any night sweats? P: Uh, no night sweats. D: OK, um have you had any changes to your vision or hearing? P: No. D: OK. Have you had any changes to your uh sense of smell or sense of taste? P: No. D: OK, have you had a runny nose or or a sore throat? P: No. D: Have you had a cough or or any shortness of breath? P: Uh no nothing like that. D: OK, how about any uh wheezing? P: No wheezing. D: Alright, any chest pain or heart palpitations? P: No. D: Alright have you had any lightheadedness or dizziness? P: No. D: Alright, and any confusion or memory loss? P: No. D: Alright, and have you had any changes in appetite, like a loss of appetite? P: Uh no, I, if anything, had a gain in appetite. D: Alright, uh have you had any nausea or vomiting? P: No. D: How about any abdominal pain? P: No. D: Alright. Um and how about any urinary problems? P: Uh no urinary problems. D: Um any changes to your bowel habits, like diarrhea or blood in the stool? P: No. D: Alright, and have you had any rashes or skin changes or changes to your hair or nails? P: No, nothing like that. D: OK, and any other joint pains? Or have you or do you have any joint swelling? P: Uh I have some joint um swelling. It's it's not very visible, but it's it appears slightly more swollen than my left, sorry, than my right knee. D: OK. So just a little bit of swelling in your left knee, but no other joints? P: No. D: OK, um and have you been diagnosed with any medical conditions before? P: Um I have um diabetes, high blood pressure and high cholesterol. And I'm overweight. D: OK, do you take any medications for any of those conditions? P: I'm on insulin for diabetes. Um I'm on Ramipril for high blood pressure and I'm also on a statin for the cholesterol. D: OK, and do you have any allergies to medications? P: No. D: Alright, and uh, have you had any surgeries in the past? P: No. D: Alright, and um are your immunizations up to date? P: I think so. D: Alright, uh, and could you tell me a little bit about your living situation currently, like like who you're living with and whereabouts? P: Um I live with my husband in a house downtown. D: OK, um and are you working currently? P: No, I retired early. D: OK, um do you drink alcohol? P: Um I'll have a glass of wine every night. D: OK, so about 7 drinks per week? P: Yes. D: OK, and um, do you smoke cigarettes? P: Uh no, I don't. D: Alright, how about the use of any recreational drugs like cannabis or uh or anything else? P: No. D: Alright. Um and is there any, uh, like musculoskeletal or like autoimmune conditions that run in the family? P: Uhm no musculoskeletal issues uh that, I know diabetes runs in the family. D: OK, um alright, so that was everything I wanted to ask on history. So next I just wanted to do a physical exam, and just looking at the left knee, are you seeing any um swelling or redness uh on the knee? P: Um it appears slightly more swollen than my right knee. D: OK, but are you seeing any redness? P: No redness. D: OK, and are there any temperature changes? Like does the knee feel hot or or warm? P: No. D: OK, and if you um press along the uh joint line, do you feel any pain? P: Uhm yeah, it feels a little tender. D: OK. And how about pain over any of the muscles, like the thigh muscles or the hamstrings or the calf muscles? P: No, those are fine. D: OK, and then how about any pain over the patella or kneecap? P: That that's a little bit more painful. D: OK, and are you able to bend your knee uh like like flex it, straighten it? P: Uh I can do that, it's just painful when I do that. D: OK. Um and uh and then how about walking, are you um, do you have an antalgic gait or or or a limp? P: Uhm no, no, well, I guess I'm I'm putting more weight on my right knee so it might appear to some people that I do have a slight limp. D: OK. And any issues with moving your hip or your ankle? P: Uh no. D: OK, um so I think that was everything I wanted to ask and check today. Did did you have any questions? P: Um yeah, so um how do you, how can I treat my knee? D: Yeah, certainly, so it it sounds like um this could be most likely osteoarthritis um of the left knee, which uh is something that would be best treated with uh trying to stay as active as you can, but but also pacing your activities as well, so that you're not um doing so much that the next day you're in significant amount of pain, but it's important to remember that um activity will help um with keeping your knee mobile, but also um actually help with reducing pain as well, and then also uh you could use Tylenol um as a medication for it. I wouldn't recommend ibuprofen or NSAIDs on a long term basis, although you could take those if you're having like an acute flare up of your pain. Um and then also like topical agents such as um like Voltaren or something like that you could put on your knee and um if it's really bad and it keeps um continuing on, we can consider something like a steroid injection as well. P: OK, yeah, that sounds good. Thank you. D: Alright, thank you.\\n\\n### Response:\\nSubjective:\\n\\nChief Complaint: I've been having this pain in my left knee for the past two months. It's getting worse and it's limiting my daily activities.\\n\\nHistory of Present Illness: The pain started two months ago and is located in the front of the knee, deep within the kneecap. It's worse with movement and after waking up in the morning. The knee feels stiff in the morning, but the stiffness goes away after 15 to 30 minutes. The pain is described as a dull ache, but can be sharp at times. The pain is made worse with activity and is not radiating anywhere else. There have been no injuries to the knee before. There has been a 20-pound weight gain over the past six months, but no changes in diet or exercise. There have been no fevers, chills, night sweats, changes in vision or hearing, runny nose, sore throat, cough, wheezing, chest pain, heart palpitations, lightheadedness, confusion, memory loss, loss of appetite, nausea, abdominal pain, urinary problems, changes to the sense of smell or taste, or rashes. There have been no changes to the hair or nails. There is some joint swelling in the left knee, but no other joint pains or swelling.\\n\\nPast Medical History: Diabetes, high blood pressure, high cholesterol, and overweight. Taking insulin for diabetes, Ramipril for high blood pressure, and a statin for cholesterol.\\n\\nMedications: Insulin for diabetes, Ramipril for high blood pressure, and a statin for cholesterol.\\n\\nAllergies: None.\\n\\nFamily History: Diabetes.\\n\\nSocial History: Retired early, lives with husband in a house downtown, drinks alcohol (7 drinks per week), and smokes cigarettes.\\n\\nPhysical Exam: Swelling and redness in the left knee, but no temperature changes. Pain with pressure over the joint line and kneecap, but no pain over the muscles or patella. Able to bend and straighten the knee, but with pain. No issues with hip or ankle movement.\\n\\nImpression: Left knee pain with stiffness in the morning, consistent with osteoarthritis.\\n\\nObjective:\\n\\nAppearance: Patient appears to be in pain and is limping.\\n\\nSkin: No rashes or skin changes.\\n\\nMusculoskeletal: Swelling and redness in the left knee, but no temperature changes. Pain with pressure over the joint line and kneecap, but no pain over the muscles or patella. Able to bend and straighten the knee, but with pain. No issues with hip or ankle movement.\\n\\nPlan:\\n\\nDiagnosis: Osteoarthritis of the left knee.\\n\\nTreatment:\\n\\nActivity: Stay as active as possible, but pace activities to avoid significant pain the next day.\\n\\nMedications: Tylenol for pain, avoid NSAIDs on a long-term basis.\\n\\nTopical Agents: Voltaren or similar topical agent for pain.\\n\"]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Testing model by doing inference with sample data\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    soap_prompt.format(\n",
        "       \"Below is an dialogue that shows conversation between doctor and patient, convert it into clinical soap format.\", # instruction\n",
        "        \"\"\"D: How may I help you? P: I'm here because um I've been having some pain in my left knee for the past two months and it's not getting better. It feels stiff and um I just haven't been able to uh, you know, use it as well, as well as I was using it before um and it's just limited some of my daily activities. D: OK, um, and where, uh so it's, the pain is in your left knee. Where are you feeling this pain specifically? Is it at the front of the knee, the sides, or or the the back? Could you point to it? P: It feels like it's mostly on the front. D: OK. P: Like deep within that um kneecap. D: OK, and you said the pain started two months ago? P: Yes, well, it's always been a little like tender. Um but now it's more painful. D: OK. And so, so has it been getting worse? P: I would say so, slowly getting worse. D: OK. Uh and when you get uh pain in the left knee, how long does it typically last for? P: It usually hurts while I'm doing, while I'm moving it, or just after, but if I if I rest, the pain eventually goes away. Um but when I first wake up in the morning, that joint feels stiff. And then when I start using it, using it more, it's less stiff, but it becomes painful. D: OK, so you have some stiffness in the morning? P: I do. D: OK, and how long does it last for? Like 30 minutes, 60 minutes or or longer? P: The stiffness or pain? D: Yeah, the the stiffness. P: Uh the stiffness goes away in like yeah 15 to 30 minutes. D: OK, and how would you describe the pain, um in terms of its character? P: It feels, it feels uh, I guess most of the time it's like it's like a dull kind of pain, but it can be sharp. D: OK, and is there anything that makes the pain worse? P: Just with a lot of activity it gets worse. D: And you feel it radiate anywhere else? P: No. D: OK, and how would you describe the severity of your pain on a scale of 10 being the worst pain you've ever felt, and 1 being kind of very minimal pain. P: Uhm, I would give it maybe uh 7. D: OK. And have you had any injuries to your knee before? P: No, not that I can think of. D: No, OK. Um and have you been having any uh any weight loss recently? P: Uh no, weight gain. D: Weight gain, OK. How much weight have you gained over the last uh several months? P: Over the past six months, I'd say I've gained about 20 pounds. D: OK, have you had changes in your diet and or exercise? P: Um I guess I've been eating a little bit more, um but no changes in exercise. D: OK. Um have you been having any fevers or chills? P: No. D: OK, how about any night sweats? P: Uh, no night sweats. D: OK, um have you had any changes to your vision or hearing? P: No. D: OK. Have you had any changes to your uh sense of smell or sense of taste? P: No. D: OK, have you had a runny nose or or a sore throat? P: No. D: Have you had a cough or or any shortness of breath? P: Uh no nothing like that. D: OK, how about any uh wheezing? P: No wheezing. D: Alright, any chest pain or heart palpitations? P: No. D: Alright have you had any lightheadedness or dizziness? P: No. D: Alright, and any confusion or memory loss? P: No. D: Alright, and have you had any changes in appetite, like a loss of appetite? P: Uh no, I, if anything, had a gain in appetite. D: Alright, uh have you had any nausea or vomiting? P: No. D: How about any abdominal pain? P: No. D: Alright. Um and how about any urinary problems? P: Uh no urinary problems. D: Um any changes to your bowel habits, like diarrhea or blood in the stool? P: No. D: Alright, and have you had any rashes or skin changes or changes to your hair or nails? P: No, nothing like that. D: OK, and any other joint pains? Or have you or do you have any joint swelling? P: Uh I have some joint um swelling. It's it's not very visible, but it's it appears slightly more swollen than my left, sorry, than my right knee. D: OK. So just a little bit of swelling in your left knee, but no other joints? P: No. D: OK, um and have you been diagnosed with any medical conditions before? P: Um I have um diabetes, high blood pressure and high cholesterol. And I'm overweight. D: OK, do you take any medications for any of those conditions? P: I'm on insulin for diabetes. Um I'm on Ramipril for high blood pressure and I'm also on a statin for the cholesterol. D: OK, and do you have any allergies to medications? P: No. D: Alright, and uh, have you had any surgeries in the past? P: No. D: Alright, and um are your immunizations up to date? P: I think so. D: Alright, uh, and could you tell me a little bit about your living situation currently, like like who you're living with and whereabouts? P: Um I live with my husband in a house downtown. D: OK, um and are you working currently? P: No, I retired early. D: OK, um do you drink alcohol? P: Um I'll have a glass of wine every night. D: OK, so about 7 drinks per week? P: Yes. D: OK, and um, do you smoke cigarettes? P: Uh no, I don't. D: Alright, how about the use of any recreational drugs like cannabis or uh or anything else? P: No. D: Alright. Um and is there any, uh, like musculoskeletal or like autoimmune conditions that run in the family? P: Uhm no musculoskeletal issues uh that, I know diabetes runs in the family. D: OK, um alright, so that was everything I wanted to ask on history. So next I just wanted to do a physical exam, and just looking at the left knee, are you seeing any um swelling or redness uh on the knee? P: Um it appears slightly more swollen than my right knee. D: OK, but are you seeing any redness? P: No redness. D: OK, and are there any temperature changes? Like does the knee feel hot or or warm? P: No. D: OK, and if you um press along the uh joint line, do you feel any pain? P: Uhm yeah, it feels a little tender. D: OK. And how about pain over any of the muscles, like the thigh muscles or the hamstrings or the calf muscles? P: No, those are fine. D: OK, and then how about any pain over the patella or kneecap? P: That that's a little bit more painful. D: OK, and are you able to bend your knee uh like like flex it, straighten it? P: Uh I can do that, it's just painful when I do that. D: OK. Um and uh and then how about walking, are you um, do you have an antalgic gait or or or a limp? P: Uhm no, no, well, I guess I'm I'm putting more weight on my right knee so it might appear to some people that I do have a slight limp. D: OK. And any issues with moving your hip or your ankle? P: Uh no. D: OK, um so I think that was everything I wanted to ask and check today. Did did you have any questions? P: Um yeah, so um how do you, how can I treat my knee? D: Yeah, certainly, so it it sounds like um this could be most likely osteoarthritis um of the left knee, which uh is something that would be best treated with uh trying to stay as active as you can, but but also pacing your activities as well, so that you're not um doing so much that the next day you're in significant amount of pain, but it's important to remember that um activity will help um with keeping your knee mobile, but also um actually help with reducing pain as well, and then also uh you could use Tylenol um as a medication for it. I wouldn't recommend ibuprofen or NSAIDs on a long term basis, although you could take those if you're having like an acute flare up of your pain. Um and then also like topical agents such as um like Voltaren or something like that you could put on your knee and um if it's really bad and it keeps um continuing on, we can consider something like a steroid injection as well. P: OK, yeah, that sounds good. Thank you. D: Alright, thank you.\"\"\", # input\n",
        "        \"\",\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "outputs = model.generate(**inputs, max_new_tokens = 700, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02666ee-032a-4558-9c10-3af3358f23e0",
      "metadata": {
        "id": "c02666ee-032a-4558-9c10-3af3358f23e0",
        "outputId": "d3aa4513-9f96-45e4-8b78-566a3833305a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Max Memory</td><td>▁▁</td></tr><tr><td>Memory Reserved for Training(GB)</td><td>▁</td></tr><tr><td>Percentage of Max Memory Reserved for Training(%)</td><td>▁</td></tr><tr><td>Reserved Memory</td><td>▁</td></tr><tr><td>Training Time(Seconds)</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▆▆▆▃▃▅█▃▁▁▃▆▃▃▂▂▃▂▂▃</td></tr><tr><td>train/learning_rate</td><td>▂▄▅▇██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>▇█▇▆▅▄▆▅▂▄▃▅▃▅▁▃▃▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GPU Stats</td><td>NVIDIA L4</td></tr><tr><td>Max Memory</td><td>21.964</td></tr><tr><td>Memory Reserved for Training(GB)</td><td>1.529</td></tr><tr><td>Percentage of Max Memory Reserved for Training(%)</td><td>6.961</td></tr><tr><td>Reserved Memory</td><td>4.547</td></tr><tr><td>Training Time(Seconds)</td><td>390.6233</td></tr><tr><td>total_flos</td><td>1.402135828758528e+16</td></tr><tr><td>train/epoch</td><td>0.16</td></tr><tr><td>train/global_step</td><td>20</td></tr><tr><td>train/grad_norm</td><td>0.43518</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2527</td></tr><tr><td>train_loss</td><td>1.34576</td></tr><tr><td>train_runtime</td><td>390.6233</td></tr><tr><td>train_samples_per_second</td><td>0.41</td></tr><tr><td>train_steps_per_second</td><td>0.051</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">mistral-7b</strong> at: <a href='https://wandb.ai/med_scribe/soap-comparision/runs/yduthrii' target=\"_blank\">https://wandb.ai/med_scribe/soap-comparision/runs/yduthrii</a><br/> View project at: <a href='https://wandb.ai/med_scribe/soap-comparision' target=\"_blank\">https://wandb.ai/med_scribe/soap-comparision</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240501_063021-yduthrii/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training Stats\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}